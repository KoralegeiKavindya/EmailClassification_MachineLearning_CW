{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.21               0.28           0.50           0.0   \n1            0.06               0.00           0.71           0.0   \n2            0.00               0.00           0.00           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.14            0.28              0.21                0.07   \n1           1.23            0.19              0.19                0.12   \n2           0.63            0.00              0.31                0.63   \n3           0.63            0.00              0.31                0.63   \n4           1.85            0.00              0.00                1.85   \n\n   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n0             0.00            0.94  ...         0.00        0.132   \n1             0.64            0.25  ...         0.01        0.143   \n2             0.31            0.63  ...         0.00        0.137   \n3             0.31            0.63  ...         0.00        0.135   \n4             0.00            0.00  ...         0.00        0.223   \n\n   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0          0.0        0.372        0.180        0.048   \n1          0.0        0.276        0.184        0.010   \n2          0.0        0.137        0.000        0.000   \n3          0.0        0.135        0.000        0.000   \n4          0.0        0.000        0.000        0.000   \n\n   capital_run_length_average  capital_run_length_longest  \\\n0                       5.114                         101   \n1                       9.821                         485   \n2                       3.537                          40   \n3                       3.537                          40   \n4                       3.000                          15   \n\n   capital_run_length_total  target_value  \n0                      1028             1  \n1                      2259             1  \n2                       191             1  \n3                       191             1  \n4                        54             1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>target_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.85</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.85</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.223</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.000</td>\n      <td>15</td>\n      <td>54</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset is being load\n",
    "spam_dataset = pd.read_csv(\"spambase.csv\")\n",
    "\n",
    "# Adding the names for the column\n",
    "spam_dataset.columns = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'target_value']\n",
    "\n",
    "# For visibility purpose, first 5 rows are being displayed\n",
    "spam_dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "(4600, 58)"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the shape of the dataset\n",
    "spam_dataset.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**This means that there are 4600 data tuples/rows and 58 data columns in this dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# Removing duplicate data rows from the dataset\n",
    "spam_dataset = spam_dataset.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "word_freq_make                0\nword_freq_address             0\nword_freq_all                 0\nword_freq_3d                  0\nword_freq_our                 0\nword_freq_over                0\nword_freq_remove              0\nword_freq_internet            0\nword_freq_order               0\nword_freq_mail                0\nword_freq_receive             0\nword_freq_will                0\nword_freq_people              0\nword_freq_report              0\nword_freq_addresses           0\nword_freq_free                0\nword_freq_business            0\nword_freq_email               0\nword_freq_you                 0\nword_freq_credit              0\nword_freq_your                0\nword_freq_font                0\nword_freq_000                 0\nword_freq_money               0\nword_freq_hp                  0\nword_freq_hpl                 0\nword_freq_george              0\nword_freq_650                 0\nword_freq_lab                 0\nword_freq_labs                0\nword_freq_telnet              0\nword_freq_857                 0\nword_freq_data                0\nword_freq_415                 0\nword_freq_85                  0\nword_freq_technology          0\nword_freq_1999                0\nword_freq_parts               0\nword_freq_pm                  0\nword_freq_direct              0\nword_freq_cs                  0\nword_freq_meeting             0\nword_freq_original            0\nword_freq_project             0\nword_freq_re                  0\nword_freq_edu                 0\nword_freq_table               0\nword_freq_conference          0\nchar_freq_;                   0\nchar_freq_(                   0\nchar_freq_[                   0\nchar_freq_!                   0\nchar_freq_$                   0\nchar_freq_#                   0\ncapital_run_length_average    0\ncapital_run_length_longest    0\ncapital_run_length_total      0\ntarget_value                  0\ndtype: int64"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting missing data values in the columns per column\n",
    "missing_data_vals = spam_dataset.isnull().sum()\n",
    "missing_data_vals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**From the above output, we can see that there are no missing values available in the dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0               0.21               0.28           0.50           0.0   \n1               0.06               0.00           0.71           0.0   \n2               0.00               0.00           0.00           0.0   \n3               0.00               0.00           0.00           0.0   \n4               0.00               0.00           0.00           0.0   \n...              ...                ...            ...           ...   \n4595            0.31               0.00           0.62           0.0   \n4596            0.00               0.00           0.00           0.0   \n4597            0.30               0.00           0.30           0.0   \n4598            0.96               0.00           0.00           0.0   \n4599            0.00               0.00           0.65           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0              0.14            0.28              0.21                0.07   \n1              1.23            0.19              0.19                0.12   \n2              0.63            0.00              0.31                0.63   \n3              0.63            0.00              0.31                0.63   \n4              1.85            0.00              0.00                1.85   \n...             ...             ...               ...                 ...   \n4595           0.00            0.31              0.00                0.00   \n4596           0.00            0.00              0.00                0.00   \n4597           0.00            0.00              0.00                0.00   \n4598           0.32            0.00              0.00                0.00   \n4599           0.00            0.00              0.00                0.00   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n0                0.00            0.94  ...                   0.0        0.000   \n1                0.64            0.25  ...                   0.0        0.010   \n2                0.31            0.63  ...                   0.0        0.000   \n3                0.31            0.63  ...                   0.0        0.000   \n4                0.00            0.00  ...                   0.0        0.000   \n...               ...             ...  ...                   ...          ...   \n4595             0.00            0.00  ...                   0.0        0.000   \n4596             0.00            0.00  ...                   0.0        0.000   \n4597             0.00            0.00  ...                   0.0        0.102   \n4598             0.00            0.00  ...                   0.0        0.000   \n4599             0.00            0.00  ...                   0.0        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0           0.132          0.0        0.372        0.180        0.048   \n1           0.143          0.0        0.276        0.184        0.010   \n2           0.137          0.0        0.137        0.000        0.000   \n3           0.135          0.0        0.135        0.000        0.000   \n4           0.223          0.0        0.000        0.000        0.000   \n...           ...          ...          ...          ...          ...   \n4595        0.232          0.0        0.000        0.000        0.000   \n4596        0.000          0.0        0.353        0.000        0.000   \n4597        0.718          0.0        0.000        0.000        0.000   \n4598        0.057          0.0        0.000        0.000        0.000   \n4599        0.000          0.0        0.125        0.000        0.000   \n\n      capital_run_length_average  capital_run_length_longest  \\\n0                          5.114                         101   \n1                          9.821                         485   \n2                          3.537                          40   \n3                          3.537                          40   \n4                          3.000                          15   \n...                          ...                         ...   \n4595                       1.142                           3   \n4596                       1.555                           4   \n4597                       1.404                           6   \n4598                       1.147                           5   \n4599                       1.250                           5   \n\n      capital_run_length_total  \n0                         1028  \n1                         2259  \n2                          191  \n3                          191  \n4                           54  \n...                        ...  \n4595                        88  \n4596                        14  \n4597                       118  \n4598                        78  \n4599                        40  \n\n[4209 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.010</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.85</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.85</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.223</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.000</td>\n      <td>15</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4595</th>\n      <td>0.31</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.232</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.142</td>\n      <td>3</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>4596</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.353</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.555</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4597</th>\n      <td>0.30</td>\n      <td>0.00</td>\n      <td>0.30</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.102</td>\n      <td>0.718</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.404</td>\n      <td>6</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>4598</th>\n      <td>0.96</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.057</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.147</td>\n      <td>5</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>4599</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.65</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.125</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>5</td>\n      <td>40</td>\n    </tr>\n  </tbody>\n</table>\n<p>4209 rows Ã— 57 columns</p>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataset with all the training data except the target value column\n",
    "X = spam_dataset.drop(columns=['target_value'])\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting and separating the target values\n",
    "Y = spam_dataset['target_value'].values\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.35203068,  0.3687239 ,  0.40452578, ..., -0.00815397,\n         0.24482253,  1.19099523],\n       [-0.14796835, -0.24776187,  0.81174673, ...,  0.13384834,\n         2.16884257,  3.18079631],\n       [-0.34796797, -0.24776187, -0.56504793, ..., -0.05572942,\n        -0.06081607, -0.16194019],\n       ...,\n       [ 0.6520301 , -0.24776187,  0.01669629, ..., -0.12007846,\n        -0.23117201, -0.27993815],\n       [ 2.85202586, -0.24776187, -0.56504793, ..., -0.12783172,\n        -0.23618248, -0.34459456],\n       [-0.34796797, -0.24776187,  0.69539789, ..., -0.12472438,\n        -0.23618248, -0.40601815]])"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Splitting and Creation of Target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# Split dataset into training (70%) and testing (30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, train_size = 0.7, random_state = 0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbor(KNN) Classification Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9300746775288526\n",
      "0.9002375296912114\n"
     ]
    }
   ],
   "source": [
    "# Create KNN Classifier model for k = 5\n",
    "k = 5\n",
    "KNN_classification = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "# Train the model using the training sets\n",
    "KNN_classification.fit(X_train,Y_train )\n",
    "\n",
    "print(KNN_classification.score(X_train, Y_train))\n",
    "print(KNN_classification.score(X_test, Y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Evaluation - Train Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Not-spam  Spam\n",
      "Not-spam      1716    78\n",
      "Spam           128  1024\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      1794\n",
      "           1       0.93      0.89      0.91      1152\n",
      "\n",
      "    accuracy                           0.93      2946\n",
      "   macro avg       0.93      0.92      0.93      2946\n",
      "weighted avg       0.93      0.93      0.93      2946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for train dataset\n",
    "train_prediction = KNN_classification.predict(X_train)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_m = confusion_matrix(y_true = Y_train, y_pred = train_prediction)\n",
    "\n",
    "print(pd.DataFrame(confusion_m, index = ['Not-spam', 'Spam'], columns = ['Not-spam', 'Spam']))\n",
    "print('-----------------------------------------------------')\n",
    "print(classification_report(y_true = Y_train, y_pred = train_prediction))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Validation  -  Test Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Not-spam  Spam\n",
      "Not-spam       693    44\n",
      "Spam            82   444\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       737\n",
      "           1       0.91      0.84      0.88       526\n",
      "\n",
      "    accuracy                           0.90      1263\n",
      "   macro avg       0.90      0.89      0.90      1263\n",
      "weighted avg       0.90      0.90      0.90      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for test dataset\n",
    "test_prediction = KNN_classification.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true = Y_test, y_pred = test_prediction)\n",
    "\n",
    "print(pd.DataFrame(cm, index = ['Not-spam', 'Spam'], columns = ['Not-spam', 'Spam']))\n",
    "print('-----------------------------------------------------')\n",
    "print(classification_report(y_true = Y_test, y_pred = test_prediction))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "(4209, 49)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.10899513, 0.05583094, 0.0353128 , 0.02858045, 0.0271153 ,\n       0.02575975, 0.02483614, 0.02398193, 0.02270325, 0.02183887,\n       0.02167963, 0.02015995, 0.02006717, 0.01935537, 0.01924267,\n       0.01866808, 0.01848522, 0.01796674, 0.0178274 , 0.01756145,\n       0.01717349, 0.01698023, 0.01672036, 0.01657472, 0.01645046,\n       0.01610422, 0.01585499, 0.01571016, 0.0153264 , 0.01517569,\n       0.01456768, 0.01435856, 0.01421106, 0.01406908, 0.01383434,\n       0.01333399, 0.01329598, 0.01301827, 0.01274202, 0.01232527,\n       0.01195466, 0.0117737 , 0.01120298, 0.01098196, 0.01036702,\n       0.01030622, 0.00936144, 0.00876401, 0.00816524])"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9566723905184702"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "49"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "X_pca\n",
    "X_train_pca, X_test_pca, Y_train, Y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9260469260469261\n",
      "0.9168646080760094\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "KNN_classification.fit(X_train_pca,Y_train )\n",
    "\n",
    "print(KNN_classification.score(X_train_pca, Y_train))\n",
    "print(KNN_classification.score(X_test_pca, Y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=3367 does not match number of samples=2946",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[114], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m decision_t_classification \u001B[38;5;241m=\u001B[39m DecisionTreeClassifier()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Train the model using the training sets\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mdecision_t_classification\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(decision_t_classification\u001B[38;5;241m.\u001B[39mscore(X_train, Y_train))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\newConda\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001B[0m, in \u001B[0;36mDecisionTreeClassifier.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m    859\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    860\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001B[39;00m\n\u001B[0;32m    861\u001B[0m \n\u001B[0;32m    862\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m    887\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 889\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    895\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\newConda\\lib\\site-packages\\sklearn\\tree\\_classes.py:302\u001B[0m, in \u001B[0;36mBaseDecisionTree.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m    299\u001B[0m max_leaf_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_leaf_nodes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_leaf_nodes\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y) \u001B[38;5;241m!=\u001B[39m n_samples:\n\u001B[1;32m--> 302\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    303\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of labels=\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m does not match number of samples=\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    304\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mlen\u001B[39m(y), n_samples)\n\u001B[0;32m    305\u001B[0m     )\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    308\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "\u001B[1;31mValueError\u001B[0m: Number of labels=3367 does not match number of samples=2946"
     ]
    }
   ],
   "source": [
    "#Create decision tree classification model\n",
    "decision_t_classification = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model using the training sets\n",
    "decision_t_classification.fit(X_train,Y_train )\n",
    "\n",
    "print(decision_t_classification.score(X_train, Y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Evaluation -  Train Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict the response for train dataset\n",
    "train_prediction = decision_t_classification.predict(X_train)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_m = confusion_matrix(y_true = Y_train, y_pred = train_prediction)\n",
    "\n",
    "print(pd.DataFrame(confusion_m, index = ['Not-spam', 'Spam'], columns = ['Not-spam', 'Spam']))\n",
    "print('-----------------------------------------------------')\n",
    "print(classification_report(y_true = Y_train, y_pred = train_prediction))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Validation -  Test Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict the response for test dataset\n",
    "test_prediction = decision_t_classification.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true = Y_test, y_pred = test_prediction)\n",
    "\n",
    "print(pd.DataFrame(cm, index = ['Not-spam', 'Spam'], columns = ['Not-spam', 'Spam']))\n",
    "print('-----------------------------------------------------')\n",
    "print(classification_report(y_true = Y_test, y_pred = test_prediction))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
